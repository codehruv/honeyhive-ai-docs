---
title: "Introduction"
description: "The developer-first LLMOps platform"
---

### What is HoneyHive?

HoneyHive is the **developer platform** that helps you build, evaluate and continuously optimize powerful LLM-powered apps with human feedback, quantitative rigor and safety best-practices. We offer powerful features that help you **manage prompts, evaluate and compare variants, monitor models in production, define custom metrics and manage datasets** across the entire ML lifecycle - helping you iterate and improve your models with confidence from prototype to production, and beyond.

![monitoring](/images/monitoring.png)

### Pre-Production

Using HoneyHive, your team can continuously iterate on your production LLM apps and evaluate any new model-prompt configurations against a wide variety of custom quantitative metrics (Unit Tests, NLP metrics or LLM-based evaluation metrics) before pushing changes to production. This helps you safely validate model performance and understand where your model may potentially underperform in production. 

After running an evaluation with HoneyHive, your team can safely deploy the best variants to production using our proxy server without having to change your backend code. This helps improve your team's iteration velocity and removes unnecessary dependencies between ML, Data Science and Engineering teams.

### In-Production

Once in production, we help you discover new insights, behaviors and anomalies by logging your LLM completion requests, user feedback, custom metrics and any user metadata. You can quickly visualize any custom metrics, compare data slices, and understand the distribution of your production data via our embeddings and clustering visualizations.

Your team can use these insights to automatically improve prompts with our `Prompt Magic` feature, re-evaluate your new model-prompt configuration against your baseline variant and run live A/B tests in production to further validate performance improvements against user feedback or any custom metrics.

### Fine-Tuning

To further optimize your costs, latency or performance, you can use your production logs to quickly fine-tune custom models across all major LLM providers or curate and export datasets to fine-tune your own custom, open-source model via third-party services such as MosaicML. Once you have fine-tuned a model, you can quickly run a quantitative evaluation against your baseline variant to validate performance improvements before deploying the new model to production.

### Integration

Our APIs and SDKs are designed to be easy to use and integrate with your existing infrastructure and the larger LLMOps ecosystem (Langchain, LlamaIndex, etc.). 

<Tip>Everything you can do via the platform can be done programmatically via the SDK.</Tip>

<br />

<CardGroup>
  <Card title="Getting Started" icon="rectangle-terminal" href="/getting-started">
    A simple guide to quickly get up and running with HoneyHive.
  </Card>
  <Card title="Python Quickstart" icon="rectangle-terminal" href="/python-quickstart">
    How to quickly get started with our Python SDK.
  </Card>
  <Card title="Javascript Quickstart" icon="rectangle-terminal" href="/js-quickstart">
    How to quickly get started with Javascript.
  </Card>
  <Card title="Go Quickstart" icon="rectangle-terminal" href="/go-quickstart">
    How to quickly get started with our Go SDK.
  </Card>
  <Card title="Concepts" icon="sliders" href="/concepts">
    Some key concepts behind our platform.
  </Card>
  <Card title="Core Capabilities" icon="ellipsis" href="/features">
    Key features and how to get value from our platform.
  </Card>
  <Card title="API Reference Guide" icon="heading" href="/api-reference/authentication">
    Our reference guide on how to integrate the HoneyHive SDK and APIs with your application.
  </Card>
  <Card title="Prompt Engineering and Fine-Tuning Guides" icon="heading" href="/resources">
    Guides for prompt engineering and fine-tuning your models.
  </Card>
</CardGroup>

<Note>Our documentation is a work in progress. If you have any questions, please reach out to us at [dhruv@honeyhive.ai](mailto:dhruv@honeyhive.ai).</Note>
