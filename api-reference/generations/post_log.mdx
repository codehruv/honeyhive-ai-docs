---
title: "Ingest Generations"
api: "POST https://honeyhive.ai:5000/generations/log"
description: "This endpoint ingests a single generation."
---

### Body

"task": "Sandbox - Email Writer",
    "inputs": {"var": "test"},
    "generation": openai_response["choices"][0]["text"],
    "model": "text-davinci-003",
    "prompt": "Say this is a {{var}}",
    "hyperparameters": {"max_tokens": 7, "temperature": 0},
    "response": openai_response,
    "source": "testing",
    "latency": latency

<ParamField 
    body="task"
    type="string"
    required>
    The project for which you are logging the generation.
</ParamField>

<ParamField 
    body="model"
    type="string"
    required>
    The model that was used to generate the text.
</ParamField>

<ParamField 
    body="hyperparameters"
    type="object"
    required>
    The hyperparameters that were used to generate the text.
</ParamField>

<ParamField 
    body="prompt"
    type="string"
    required>
    The prompt that was used to generate the text. Make sure it has the variables in brackets like this - '{{var}}'
</ParamField>

<ParamField 
    body="inputs"
    type="object"
    required>
    The inputs filled into the prompt.
</ParamField>

<ParamField 
    body="generation"
    type="string"
    required>
    The text that was generated by your model provider.
</ParamField>

<ParamField 
    body="response"
    type="object"
    required>
    The full response from your model provider.
</ParamField>

<ParamField 
    body="source"
    type="string">
    The source of the generation. This can be anything you want to use to track the generation source.
</ParamField>

<ParamField 
    body="latency"
    type="number">
    The latency of the generation in milliseconds.
</ParamField>

### Response


<ResponseField name="version" type="string">
  This is the model version used for the generation. If not specified, we will use the source as a version.
</ResponseField>

<ResponseField name="generation" type="string">
  This is the generated completion.
</ResponseField>

<ResponseField name="generation_id" type="string">
  This is the unique identifier for the generation.
</ResponseField>

<ResponseField name="total_tokens" type="integer">
  This is the total number of tokens used for the generation.
</ResponseField>

<ResponseField name="completion_tokens" type="integer">
  This is the number of tokens used for the completion.
</ResponseField>

<ResponseField name="cost" type="float">
  This is the cost of the generation.
</ResponseField>

<ResponseField name="latency" type="float">
  This is the latency of the generation.
</ResponseField>

<RequestExample>

```bash Example Request
curl --location --request POST 'https://honeyhive.ai:5000/generations/log' \
--header 'Content-Type: application/json' \
--header 'Authorization: Token <token>' \
--data-raw '{
    "task": "Sandbox - Email Writer",
    "model": "text-davinci-003",
    "hyperparameters": {"max_tokens": 7, "temperature": 0},
    "prompt": "Say this is a {{var}}",
    "inputs": {"var": "test"},
    "generation": "This is a generated completion from OpenAI.",
    "response": {'id': 'cmpl-6oIrGYG5V1GJi57QhsoGWOs1AHwb7', 'object': 'text_completion', 'created': 1677446910, 'model': 'text-davinci-003', 'choices': [{'text': '\n\nThis is indeed a test', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 5, 'completion_tokens': 7, 'total_tokens': 12}},
    "source": "testing",
    "latency": 1500
}'
```

</RequestExample>

<RequestExample>

```bash Example Request
{
    "version": "testing",
    "generation": "\n\nThis is indeed a test",
    "generation_id": "63fbcf009b2e533da5d865ae",
    "total_tokens": 12,
    "completion_tokens": 7,
    "cost": 0.00024,
    "latency": 915.4
}
```