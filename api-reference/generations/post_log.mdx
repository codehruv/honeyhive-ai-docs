---
title: "Ingest Single Generation"
api: "POST https://honeyhive.ai:5000/generations/log"
description: "This endpoint ingests a single generation."
---

### Body

<ParamField body="task" type="string" required>
    The project for which you are logging the generation.
</ParamField>

<ParamField body="model" type="string" required>
    The model that was used to generate the text.
</ParamField>

<ParamField body="hyperparameters" type="object" required>
    The hyperparameters that were used to generate the text.
</ParamField>

<ParamField body="prompt_template" type="string">
    Prompt used to generate the text, to be used if you don't have a prompt template with inputs defined.
</ParamField>

<ParamField body="prompt_template" type="string">
    The prompt template that was used to generate the text. Make sure it has the variables in brackets like this - `{{var}}`
</ParamField>

<ParamField body="inputs" type="object">
    The inputs filled into the prompt. This is a dictionary which specifies the values filled into the prompt template.
</ParamField>

<ParamField body="generation" type="string" required>
    The text that was generated by your model provider.
</ParamField>

<ParamField body="usage" type="object">
    The token usage for the generation. This is extracted from the response from the model provider.
</ParamField>

<ParamField body="source" type="string">
    The source of the generation. This can be anything you want to use to track the generation source.
</ParamField>

<ParamField body="latency" type="number">
    The latency of the generation in milliseconds.
</ParamField>

### Response

<ResponseField name="generation_id" type="string">
  This is the unique identifier for the generation.
</ResponseField>


<RequestExample>

```bash Example Request
curl --location --request POST 'https://honeyhive.ai:5000/generations/log' \
--header 'Content-Type: application/json' \
--header 'Authorization: Token <token>' \
--data-raw '{
    "task": "Sandbox - Email Writer",
    "model": "text-davinci-003",
    "hyperparameters": {"max_tokens": 7, "temperature": 0},
    "prompt": "Say this is a {{var}}",
    "inputs": {"var": "test"},
    "generation": "This is a generated completion from OpenAI.",
    "usage": {"prompt_tokens": 3, "completion_tokens": 7, "total_tokens": 10}
    "source": "testing",
    "latency": 1500
}'
```

</RequestExample>

<ResponseExample>

```bash Example Response
{
    "generation_id": "63fbcf009b2e533da5d865ae"
}
```

</ResponseExample>