---
title: "Javascript Quickstart"
description: "Getting started with HoneyHive via Javascript"
---

<Note>In this tutorial, we will use `axios` to send the request. You can adapt this to `fetch` as needed.</Note>

### Get API Key

After signing up on the app, you can find your API key in the [Settings](https://app.honeyhive.ai/settings/account) page under Account.

### HoneyHive Proxy Method

You can leverage our prompt CI/CD capabilities and automatically call the current deployed prompt within a specified project without specifying all the parameters. Using this method, we automatically route your requests to the model-prompt configuration that you choose to deploy within the platform.

More documentation can be found on our [saved prompt generations API page](/api-reference/generations/post_saved).

```javascript
const honeyhiveAxios = axios.create({
  headers: {
    "Authorization": "Bearer ${api_token}"
  }
});

const response = await honeyhiveAxios.post(
  'https://honeyhive.ai:5000/generations', 
  {
     "task": "Sandbox - Email Writer",
     "input": {
        topic: "INSERT_INPUT",
        tone: "INSERT_INPUT"  
    }
  }
);
var generationId = response.data.generation_id;
```

### Ingest Model Completions


Alternatively, we provide you the option to run model completion requests within your own servers and ingest the response later without using HoneyHive's proxy server via our [logging api](/api-reference/generations/post_log). We take in all the typical model provider parameters along with `task`, `source`, `latency` as HoneyHive specific parameters.

<Note>Using this method, you will not be able to use our Prompt CI/CD capabilities within the platform and will need to manually update your prompt, model provider and hyperparamater settings when deploying new variants to production.</Note>

```javascript
var url = 'https://honeyhive.ai:5000/generations/log';
const config = {
    headers: { Authorization: Bearer ${api_token} }
};

var data = {
    // honeyhive params
    "task": "PROJECT_NAME",
    "source": "testing",
    "latency": 1500,

    // model provider params
    "model": "gpt-3.5-turbo",
    "hyperparameters": {"max_tokens": 1000, "temperature": 1},
    "prompt_template": "Say this is a {{var}}",
    "inputs": {"var": "test"},
    "generation": "This is a generated completion from OpenAI.",
    "usage": openaiResponse.usage // example: {"prompt_tokens": 3, "completion_tokens": 7, "total_tokens": 10},
};


var response = await axios.create(config).post(url, data);
response = await response.data;
var generationId = response.generation_id;
```

<Note>Instead of providing a prompt_template with inputs, you can provide just a prompt if your prompt can't be templated. Refer to our [generation ingestion API docs](/api-reference/generations/post_log) for more details.</Note>

### Log User Feedback and Metadata

Using the `generation_id` that is returned, you can then send arbitrary feedback to HoneyHive using the `feedback` endpoint. 

<Tip>We recommend providing a unique user identifier along with each request as production best-practice when deploying models to production.</Tip>


```javascript
const config = {
    headers: { Authorization: Bearer ${api_token} }
};
axios.create(config).post('https://honeyhive.ai:5000/feedback', {
    generation_id: generationId,
    task: "PROJECT_NAME",
    feedback_json: {
        "num_turns": 5,
        "accepted": true,
        "rating": 5,
        "user_country": "US",
        "user_language": "en",
    }
})
```
